# Your openai api key. (required)
OPENAI_API_KEY=sk-xxxx

# Access password, separated by comma. (optional)
CODE=your-password

# You can start service behind a proxy. (optional)
PROXY_URL=http://localhost:7890

# (optional)
# Default: Empty
# Google Gemini Pro API key, set if you want to use Google Gemini Pro API.
GOOGLE_API_KEY=

# (optional)
# Default: https://generativelanguage.googleapis.com/
# Googel Gemini Pro API url without pathname, set if you want to customize Google Gemini Pro API url.
GEMINI_BASE_URL=

# Override openai api request base url. (optional)
# Default: https://api.openai.com
# Examples: http://your-openai-proxy.com
BASE_URL=

# Specify OpenAI organization ID.(optional)
# Default: Empty
OPENAI_ORG_ID=

# (optional)
# Default: Empty
# If you do not want users to use GPT-4, set this value to 1.
DISABLE_GPT4=

# (optional)
# Default: Empty
# If you do not want users to input their own API key, set this value to 1.
HIDE_USER_API_KEY=

# (optional)
# Default: Empty
# If you do want users to query balance, set this value to 1.
ENABLE_BALANCE_QUERY=

# (optional)
# Default: Empty
# If you want to disable parse settings from url, set this value to 1.
DISABLE_FAST_LINK=

# (optional)
# Default: 1
# If your project is not deployed on Vercel, set this value to 1.
NEXT_PUBLIC_ENABLE_NODEJS_PLUGIN=1

# (optional)
# Default: Empty
# If you want to enable RAG, set this value to 1.
ENABLE_RAG=

# (optional)
# Default: Empty
# Model used when RAG vectorized data.
RAG_EMBEDDING_MODEL=text-embedding-ada-002

# Configuration is required when turning on RAG.
# Default: Empty
QDRANT_URL=

# Configuration is required when turning on RAG.
# Default: Empty
QDRANT_API_KEY=

# (optional)
# Default: Empty
# Put your cookies at bilibili.com here in the exact format as in the Cookie header in HTTP. Usually it works without cookies. Leaving this empty will disable searching and fetching videos' conclusion data from Bilibili.
BILIBILI_COOKIES=

# (optional)
# Default: Empty
# Address of the metaprocess server for advanced video processing features (currently music recognition). Leaving this empty will disable them.
BILIVID_METAPROCESS_SERVER_ADDRESS=
# Default: Empty
# To control custom models, use + to add a custom model, use - to hide a model, use name=displayName to customize model name, separated by comma.
CUSTOM_MODELS=

# (optional)
# Default: Empty
# Change default model
DEFAULT_MODEL=

# anthropic claude Api Key.(optional)
ANTHROPIC_API_KEY=

### anthropic claude Api version. (optional)
ANTHROPIC_API_VERSION=

### anthropic claude Api url (optional)
ANTHROPIC_URL=

### (optional)
WHITE_WEBDAV_ENDPOINTS=

# (optional)
# Default: zh-CN-YunxiNeural
# voiceName a string with any `ShortName`. A list of all available neural voices can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support#neural-voices). However, it is not limited to neural voices: standard voices can also be used. A list of standard voices can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support#standard-voices)
EDGE_TTS_VOICE_NAME=